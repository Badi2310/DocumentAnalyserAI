import locale
locale.getpreferredencoding = lambda: "UTF-8"

import streamlit as st
import os
import dotenv
import uuid

from dotenv import load_dotenv
from mistralai import Mistral
from langchain_mistralai import ChatMistralAI
from langchain_core.messages import HumanMessage, AIMessage

from imp1 import (
    load_pdf_to_db,
    stream_llm_response,
    stream_llm_rag_response,
)

dotenv.load_dotenv()

MODELS = ["mistral-large-latest"]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Streamlit
st.set_page_config(
    page_title="Language Chain MistralAI",
    page_icon="üìë",
    layout="centered",
    initial_sidebar_state="expanded",
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.markdown("""<h2 style="text-align: center;">üìëüîç <i>–ü—Ä–æ–µ–∫—Ç LLM RAG</i></h2>""", unsafe_allow_html=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Å–µ—Å—Å–∏–∏

if "rag_sources" not in st.session_state:
    st.session_state.rag_sources = []  # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è RAG

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"}
    ]  # –ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞

# –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
def clear_chat():
    st.session_state.messages = [{"role": "assistant", "content": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"}]

st.button("–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç", on_click=clear_chat, type="primary")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
uploaded_files = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã",
    type=["pdf", "txt", "docx", "md"],
    accept_multiple_files=True,
    key="rag_docs",
)

if uploaded_files:
    st.session_state.rag_sources.extend(uploaded_files)
    for file in uploaded_files:
        if file.type == "application/pdf":
            load_pdf_to_db(file)
    st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
llm_stream = ChatMistralAI(
    model_name="mistral-large-latest",
    temperature=0.3,
    streaming=True
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ st.chat_input
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'rag_sources' not in st.session_state:
    st.session_state.rag_sources = []

if "vector_db" not in st.session_state:
    st.session_state.vector_db = None


if prompt := st.chat_input("–í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"):
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # –°–æ–∑–¥–∞—ë–º placeholder –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞
        placeholder = st.empty()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏
        messages = [
            HumanMessage(content=m["content"]) if m["role"] == "user" else AIMessage(content=m["content"])
            for m in st.session_state.messages
        ]
        

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        if st.session_state.rag_sources:  # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º RAG
            response_stream = stream_llm_rag_response(messages)
        else:  # –ò–Ω–∞—á–µ –æ–±—ã—á–Ω—ã–π LLM
            response_stream = stream_llm_response(llm_stream, messages)

        full_response = ""
        for chunk in response_stream:
            full_response += str(chunk)
            # –û–±–Ω–æ–≤–ª—è–µ–º placeholder —Å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º (–ø–ª–∞–≤–Ω—ã–π –≤—ã–≤–æ–¥)
            placeholder.markdown(full_response, unsafe_allow_html=True)

        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        st.session_state.messages.append({"role": "assistant", "content": full_response})

